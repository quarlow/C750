{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling - Open Street Map\n",
    "### Introdcution\n",
    "\n",
    "For my Open Street Map project I selected a section of map that I am familiar with.  This is a subset of Salt Lake City, Utah.  I selected the area contained within the sourthern loop of Interstate 215.  \n",
    "\n",
    "Roughly this area: https://www.openstreetmap.org/#map=12/40.6856/-111.8770 \n",
    "\n",
    "The overall process for this project was to download the xml file from Open Street Map, saved as 215S.xml.  The file was then renamed to 215S.osm for use in this project.\n",
    "\n",
    "In this area, and Salt Lake City in general, a common street naming convention is to use the ordinal direction from the center of the city.  Many streets do not have a name, they are called \"2700 South\", \"1300 East\", etc.  I expect to find many of these streets to use abberviations like \"2700 S\".  \n",
    "\n",
    "I will build a dictionary of street names and then a translation to correct any abbreviations to the full version of the street name.  I expect to find the standard types of street names also, Ave -> Avenue, Ln -> Lane, etc.  Once all the street names are corrected, the data will be exported into csv files to be imported into a MySQL database hosted locally on my PC.  The data will be analyzed using SQL queries.\n",
    "\n",
    "### Step 1\n",
    "Parse file and count tags.  The osm file is imported, and parsed through to list the tags and count the elements per tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'note': 1,\n",
       " 'meta': 1,\n",
       " 'bounds': 1,\n",
       " 'node': 330194,\n",
       " 'tag': 216705,\n",
       " 'nd': 386282,\n",
       " 'way': 47187,\n",
       " 'member': 13906,\n",
       " 'relation': 518,\n",
       " 'osm': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the file to be used for analysis\n",
    "osmfile = \"215s.osm\"\n",
    "\n",
    "# Import python file with tag and key count functions\n",
    "import parse_count\n",
    "    \n",
    "# Call function to count tags\n",
    "parse_count.count_tags(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Check k tags.  The k tags are checked for colons and problem characters.  Problem characters will make the data harder to analyze and may need to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 88018, 'lower_colon': 113926, 'problemchars': 0, 'other': 14761}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call function to count keys\n",
    "parse_count.key_count(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Audit function\n",
    "\n",
    "First ran audit with just values of Street, Avenue, and Drive.  Added values based on data as valid street types.  Salt Lake City has a lot of streets that do not have names, that just have a value based on the grid system.  Many streets were found with cardinal directions, such as 2700 South, 1300 East, etc.  These will also be found a lot in values to clean N becomes North, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'S': {'2100 S',\n",
       "              '2300 S',\n",
       "              '3300 S',\n",
       "              '895 E 4500 S',\n",
       "              'E 2100 S',\n",
       "              'E 3300 S',\n",
       "              'W 2100 S'},\n",
       "             'Rd': {'Redwood Rd', 'S Redwood Rd'},\n",
       "             'Dr': {'Atherton Dr',\n",
       "              'Executive Park Dr',\n",
       "              'Highland Dr',\n",
       "              'Ironwood Dr',\n",
       "              'Millrock Dr',\n",
       "              'S Highland Dr',\n",
       "              'W Levoy Dr'},\n",
       "             'E': {'4400 S 700 E', '4670 S 2300 E'},\n",
       "             'street': {'State street'},\n",
       "             'St': {'S State St'},\n",
       "             '100': {'Myrtle Ave Ste 100', 'West Parkway Boulevard Suite 100'},\n",
       "             'W.': {'S. 400 W.'},\n",
       "             'Ave': {'1215 East Wilmington Ave'},\n",
       "             'Cir': {'Quail Grove Cir'},\n",
       "             '84119': {'3540 2200 W\\nSalt Lake City, UT 84119'},\n",
       "             '102': {'E 3900 S, #102'},\n",
       "             's': {'East Downington Ave s'},\n",
       "             '2100S': {'2100S'},\n",
       "             'Temple': {'West Temple'},\n",
       "             'Blvd': {'Constitution Blvd', 'S Decker Lake Blvd'},\n",
       "             'Alexander': {'Alexander'},\n",
       "             'Ln': {'Nightjar Ln'},\n",
       "             'W': {'2700 W'},\n",
       "             'Pl': {'Gazebo Pl'},\n",
       "             '2000': {'2000'},\n",
       "             'Frontage': {'1300 East Frontage'},\n",
       "             'Parkways': {'Cottonwood Parkways'}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import audit function\n",
    "import audit\n",
    "\n",
    "# Call audit function.\n",
    "audit.audit_file(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappings\n",
    "\n",
    "Based on results of audit values are created in a mapping dictionary to correct for abbreviated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 S => 2300 South\n",
      "W 2100 S => W 2100 South\n",
      "E 2100 S => E 2100 South\n",
      "895 E 4500 S => 895 E 4500 South\n",
      "E 3300 S => E 3300 South\n",
      "3300 S => 3300 South\n",
      "2100 S => 2100 South\n",
      "Redwood Rd => Redwood Road\n",
      "S Redwood Rd => S Redwood Road\n",
      "Executive Park Dr => Executive Park Drive\n",
      "Ironwood Dr => Ironwood Drive\n",
      "S Highland Dr => S Highland Drive\n",
      "W Levoy Dr => W Levoy Drive\n",
      "Millrock Dr => Millrock Drive\n",
      "Highland Dr => Highland Drive\n",
      "Atherton Dr => Atherton Drive\n",
      "4400 S 700 E => 4400 S 700 East\n",
      "4670 S 2300 E => 4670 S 2300 East\n",
      "S State St => S Streetate Street\n",
      "S. 400 W. => S. 400 West\n",
      "1215 East Wilmington Ave => 1215 East Wilmington Avenue\n",
      "Quail Grove Cir => Quail Grove Circle\n",
      "East Downington Ave s => EaSoutht Downington Ave South\n",
      "Constitution Blvd => Constitution Boulevard\n",
      "S Decker Lake Blvd => S Decker Lake Boulevard\n",
      "Nightjar Ln => Nightjar Lane\n",
      "2700 W => 2700 West\n",
      "Gazebo Pl => Gazebo Place\n"
     ]
    }
   ],
   "source": [
    "import update\n",
    "                \n",
    "# pass the osm file through the function to correct the street types\n",
    "update.fix_street(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to csv files\n",
    "\n",
    "With the data imported, and the stree names fixed, the data is now exported to csv files that will be imported into a MySQL database.\n",
    "\n",
    "Functions are found in export.py file.  \n",
    "\n",
    "schema.py defines the schema used for the files that will be duplicated in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import export\n",
    "                    \n",
    "export.process_map(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### MySQL database set up\n",
    "I installed MySQL server on my local machine.  I ran in compatibility issues with importing the data.  I also installed MySQL Workbench and used that for running the SQL.  \n",
    "\n",
    "I created a schema called OSM in my database, and created the 5 tables to match the csv export.  See CreateTables.sql for the SQL that was used to create the tables.  I also created a quick DropTables.sql script for dropping the tables becasue I ended up changeing the schema details a few times.  For example, I initially had all the id values as int datatype, but the values from my export contained some records with an out of range value, so I changed them all to bigint.  I also had problems with using a column name \"key\" as a protected term, I updated the tables to use \"key2\" instead.\n",
    "\n",
    "\n",
    "### Importing the data\n",
    "The built in import wizard for MySQL workbench was very slow, pacing to take more than a day to import all the records from the csv files.  I tried to use the infile command in MySQL Workbench, but ran into permission issues.  A security feature of MySQL 8 does not allow this command.  I tried to import the data using Toad for MySQL, but ran into security issues as MySQL does not allow cached passwords for version 8, and Toad could not connect.  I had to uninstall MySQL Server 8 and locate MySQL Server 5.7 installation file.  Once I downgraged to MySQL 5.7, and created the schema and tables again, I was able to import the data using Toad.\n",
    "\n",
    "### Summary of imported data\n",
    "The size of the csv files created were:\n",
    "* nodes.csv - 29 MB\n",
    "* nodes_tags.csv - 670 KB\n",
    "* ways.csv = 2.9 MB\n",
    "* ways_nodes.csv - 9 MB\n",
    "* ways_tags.csv - 6.6 MB\n",
    "\n",
    "\n",
    "The record counts for the data once imported were:\n",
    "* SELECT Count(*) FROM nodes;\n",
    "    * 330194\n",
    "* SELECT Count(*) FROM nodes_tags;\n",
    "    * 18090\n",
    "* SELECT Count(*) FROM ways;\n",
    "    * 47187\n",
    "* SELECT Count(*) FROM ways_nodes;\n",
    "    * 386282\n",
    "* SELECT Count(*) FROM ways_tags;\n",
    "    * 184320\n",
    "\n",
    "### High level analysis of data\n",
    "\n",
    "I ran this query to check some user statistics:\n",
    "```\n",
    "SELECT user, sum(qty) as total \n",
    "from (\n",
    "SELECT user, count(*) as qty from nodes group by user\n",
    "union all\n",
    "select user, count(*) as qty from ways group by user\n",
    ") as sub \n",
    "group by user \n",
    "order by total desc, user asc\n",
    "```\n",
    "\n",
    "I got back a list of 558 unique user names for edits.  The top 5 users were are listed below.  I also made a change myself in Open Street Map before exporting the data.  My edit is found in the data, under username 'quarlow'.  My edit created a total of 5 edits across the ways and nodes tables.  I added a local park that is new and not yet included in the data.  I combined the users from the nodes table and the ways table to get a complete list of users in the dataset.\n",
    "\n",
    "| User | Total |\n",
    "|------|-------|\n",
    "|UtahBuildingsImport|99517|\n",
    "|chadbunn|80802|\n",
    "|osmjwh|72063|\n",
    "|mash84121|12153|\n",
    "|mvexel|11664|\n",
    "|...|...|\n",
    "|quarlow|5|\n",
    "\n",
    "\n",
    "### Church Types\n",
    "I took a look at what denomination of churches have been input into the data for this area.  Salt Lake City is a predominantly Mormon area.  I wanted to see how skewed the records for churches would be to support or contradict that observation.  I used this SQL:\n",
    "\n",
    "```\n",
    "SELECT value as Religion, count(*) as total\n",
    "FROM osm.nodes_tags\n",
    "WHERE key2 = 'denomination'\n",
    "GROUP BY value;\n",
    "```\n",
    "\n",
    "|Religion|Total|\n",
    "|--|--|\n",
    "|\"latter_day_saints|1|\n",
    "|baptist|6|\n",
    "|catholic|2|\n",
    "|foursquare|1|\n",
    "|jehovahs_witness|1|\n",
    "|lutheran|3|\n",
    "|mormon|75|\n",
    "|presbyterian|3|\n",
    "\n",
    "The Mormon religion's official name is The Church of Jesus Christ of Latter Day Saints.  The record for \"latter_day_saints is also another method of identifying as Mormon.  I will also exclude the foursquare record, and that may be an error.  The updated numbers are:\n",
    "\n",
    "|Religion|Total|\n",
    "|--|--|\n",
    "|baptist|6|\n",
    "|catholic|2|\n",
    "|jehovahs_witness|1|\n",
    "|lutheran|3|\n",
    "|mormon|76|\n",
    "|presbyterian|3|\n",
    "\n",
    "There are 91 total records that indicate a denomination, of those 76 are Mormon, or 84%.  This supports the observation of a predominantly Mormon population in this area.\n",
    "\n",
    "### Possible improvements of data\n",
    "\n",
    "The religion data provided two records that appear suspect.  This would be one possible way to improve the data, to update the latter_day_saint data to mormon, and to remove the foursquare record.  The impact of this change would be small, as it's only 2 records.  But applied to a larger area of Salt Lake City, or the Wastach Front would have positive impact.  The method for fixing this would be similar to the street type example earlier. A dicitonary of observed values would be created and a mapping used to correct and update any inconsistent values.  Religion can be a sensitive topic, and changing the values to something else could offend the users that imput the data.  Making modifications to religion data may provide cleaner summaries, but by changing the identified religion it may misrepresent how the population actually identifies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
